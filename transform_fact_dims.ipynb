{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here - Done\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['etl.cfg']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('etl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data_source = config.get('DIR','INPUT_DIR')\n",
    "output_processed_data = config.get('DIR','OUTPUT_DIR')\n",
    "\n",
    "i94immi_dataset = config.get('DATA','I94_IMMI')\n",
    "worldtempe_dataset = config.get('DATA','WORLD_TEMPE')\n",
    "citydemo_dataset = config.get('DATA','CITY_DEMOGRAPHIC')\n",
    "airport_dataset = config.get('DATA','AIR_PORT')\n",
    "saslabel_dataset = config.get('DATA','SAS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session - Using for droduction only\n",
    "spark = SparkSession.builder\\\n",
    "            .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "            .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "            .enableHiveSupport()\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "func =  udf (lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transform to dim_datetime tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read out from staging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- I94 Immigration staging table: `i94immi_table`\n",
    "- World Temperature staging table: `worldtempe_table`\n",
    "- I94PORT staging table `i94port_table` from SAS_Labels_Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Fact table `fact_immi_weather` wraps informations from datasets to analyze relation between traveller traffic and weather on a specific city.\n",
    "- Dim table of date that immigration happen `dim_datetime`.\n",
    "- Dim table of airport that immigration allows `dim_port`.\n",
    "- Dim table of immigration records `dim_immi_traveller`.\n",
    "- Dim table of measure times `dim_us_temperature`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|    cicid| i94yr|i94mon|       arrival_date|i94res|i94port|arrdate|i94addr|     departure_date|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|5341351.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341352.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341353.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341354.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341355.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341356.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NY|2016-05-08 00:00:00|\n",
      "|5341357.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-01 00:00:00|\n",
      "|5341358.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-02 00:00:00|\n",
      "|5341359.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-07 00:00:00|\n",
      "|5341367.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|   null|2016-04-30 00:00:00|\n",
      "|5341368.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|   null|2016-04-30 00:00:00|\n",
      "|5341371.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-05-13 00:00:00|\n",
      "|5341372.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-05-13 00:00:00|\n",
      "|5341373.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-06-01 00:00:00|\n",
      "|5341374.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341375.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341376.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341377.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341378.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-02 00:00:00|\n",
      "|5341379.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-02 00:00:00|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df = spark.read.options(inferSchema=\"true\", delimiter=\",\", header = \"true\").csv(\"i94immi_df_clean\")\n",
    "i94immi_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- arrival_date: timestamp (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- departure_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table here\n",
    "i94immi_df.createOrReplaceTempView('i94immi_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|    cicid| i94yr|i94mon|       arrival_date|i94res|i94port|arrdate|i94addr|     departure_date|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|5341351.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341352.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341353.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM i94immi_table\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            cicid,\n",
    "            arrival_date,\n",
    "            YEAR(arrival_date) as i94yr,\n",
    "            MONTH(arrival_date) as i94mon,\n",
    "            i94res,\n",
    "            i94port,\n",
    "            arrdate,\n",
    "            i94addr,\n",
    "            departure_date\n",
    "        FROM i94immi_table\n",
    "            \"\"\").createOrReplaceTempView('i94immi_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-----+------+------+-------+-------+-------+-------------------+\n",
      "|    cicid|       arrival_date|i94yr|i94mon|i94res|i94port|arrdate|i94addr|     departure_date|\n",
      "+---------+-------------------+-----+------+------+-------+-------+-------+-------------------+\n",
      "|5341351.0|2016-04-28 00:00:00| 2016|     4| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341352.0|2016-04-28 00:00:00| 2016|     4| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341353.0|2016-04-28 00:00:00| 2016|     4| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "+---------+-------------------+-----+------+------+-------+-------+-------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM i94immi_table\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|amount_i94immi_rows|\n",
      "+-------------------+\n",
      "|            2465314|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_i94immi_rows\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|        dt|averagetemperature|averagetemperatureuncertainty|   city|dt_converted|      country|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|1960-02-01|             4.995|                        0.325|ABILENE|  1960-02-01|United States|\n",
      "|1960-03-01| 8.575000000000001|                        0.303|ABILENE|  1960-03-01|United States|\n",
      "|1960-04-01|            18.452|                        0.282|ABILENE|  1960-04-01|United States|\n",
      "|1960-05-01|            21.709|          0.28600000000000003|ABILENE|  1960-05-01|United States|\n",
      "|1960-06-01|            27.714|                        0.387|ABILENE|  1960-06-01|United States|\n",
      "|1960-07-01|            27.646|                        0.326|ABILENE|  1960-07-01|United States|\n",
      "|1960-08-01|            27.481|                        0.341|ABILENE|  1960-08-01|United States|\n",
      "|1960-09-01|            24.413|                        0.241|ABILENE|  1960-09-01|United States|\n",
      "|1960-10-01|18.929000000000002|          0.28600000000000003|ABILENE|  1960-10-01|United States|\n",
      "|1960-11-01|            12.531|                        0.235|ABILENE|  1960-11-01|United States|\n",
      "|1960-12-01|             4.114|                        0.214|ABILENE|  1960-12-01|United States|\n",
      "|1961-01-01|             3.827|                        0.337|ABILENE|  1961-01-01|United States|\n",
      "|1961-02-01|              7.63|                        0.349|ABILENE|  1961-02-01|United States|\n",
      "|1961-03-01|12.799000000000001|                        0.329|ABILENE|  1961-03-01|United States|\n",
      "|1961-04-01|            17.142|                        0.397|ABILENE|  1961-04-01|United States|\n",
      "|1961-05-01|            22.582|                        0.254|ABILENE|  1961-05-01|United States|\n",
      "|1961-06-01|             24.53|                        0.333|ABILENE|  1961-06-01|United States|\n",
      "|1961-07-01|            25.783|                         0.24|ABILENE|  1961-07-01|United States|\n",
      "|1961-08-01|26.052000000000003|                        0.205|ABILENE|  1961-08-01|United States|\n",
      "|1961-09-01|22.875999999999998|                        0.391|ABILENE|  1961-09-01|United States|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df = spark.read.csv(\"worldtempe_df_clean.csv\", header=True)\n",
    "worldtempe_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- averagetemperature: string (nullable = true)\n",
      " |-- averagetemperatureuncertainty: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- dt_converted: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>averagetemperature</th>\n",
       "      <th>averagetemperatureuncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>dt_converted</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>4.995</td>\n",
       "      <td>0.325</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>8.575000000000001</td>\n",
       "      <td>0.303</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>18.452</td>\n",
       "      <td>0.282</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>21.709</td>\n",
       "      <td>0.28600000000000003</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-06-01</td>\n",
       "      <td>27.714</td>\n",
       "      <td>0.387</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-06-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt averagetemperature averagetemperatureuncertainty     city  \\\n",
       "0  1960-02-01              4.995                         0.325  ABILENE   \n",
       "1  1960-03-01  8.575000000000001                         0.303  ABILENE   \n",
       "2  1960-04-01             18.452                         0.282  ABILENE   \n",
       "3  1960-05-01             21.709           0.28600000000000003  ABILENE   \n",
       "4  1960-06-01             27.714                         0.387  ABILENE   \n",
       "\n",
       "  dt_converted        country  \n",
       "0   1960-02-01  United States  \n",
       "1   1960-03-01  United States  \n",
       "2   1960-04-01  United States  \n",
       "3   1960-05-01  United States  \n",
       "4   1960-06-01  United States  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt', 'string'),\n",
       " ('averagetemperature', 'string'),\n",
       " ('averagetemperatureuncertainty', 'string'),\n",
       " ('city', 'string'),\n",
       " ('dt_converted', 'string'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "worldtempe_df = worldtempe_df.withColumn(\"averagetemperature\", worldtempe_df[\"averagetemperature\"].cast(DoubleType()).alias(\"averagetemperature\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|        dt|averagetemperature|averagetemperatureuncertainty|   city|dt_converted|      country|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|1960-02-01|             4.995|                        0.325|ABILENE|  1960-02-01|United States|\n",
      "|1960-03-01| 8.575000000000001|                        0.303|ABILENE|  1960-03-01|United States|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df = worldtempe_df.withColumn('dt_converted', func(col('dt_converted')))\n",
    "worldtempe_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt', 'string'),\n",
       " ('averagetemperature', 'double'),\n",
       " ('averagetemperatureuncertainty', 'string'),\n",
       " ('city', 'string'),\n",
       " ('dt_converted', 'date'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# worldtempe_table here\n",
    "worldtempe_df.createOrReplaceTempView('worldtempe_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|amount_worldtempe_rows|\n",
      "+----------------------+\n",
      "|                165508|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_worldtempe_rows\n",
    "    FROM worldtempe_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            dt_converted,\n",
    "            MONTH(worldtempe_table.dt_converted) as tempe_month,\n",
    "            YEAR(worldtempe_table.dt_converted) as tempe_year,\n",
    "            dt,\n",
    "            city,\n",
    "            averagetemperature,\n",
    "            averagetemperatureuncertainty\n",
    "        FROM worldtempe_table\n",
    "            \"\"\").createOrReplaceTempView('worldtempe_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------+----------+-------+------------------+-----------------------------+\n",
      "|dt_converted|tempe_month|tempe_year|        dt|   city|averagetemperature|averagetemperatureuncertainty|\n",
      "+------------+-----------+----------+----------+-------+------------------+-----------------------------+\n",
      "|  1960-02-01|          2|      1960|1960-02-01|ABILENE|             4.995|                        0.325|\n",
      "|  1960-03-01|          3|      1960|1960-03-01|ABILENE| 8.575000000000001|                        0.303|\n",
      "|  1960-04-01|          4|      1960|1960-04-01|ABILENE|            18.452|                        0.282|\n",
      "+------------+-----------+----------+----------+-------+------------------+-----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM worldtempe_table\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        city,\n",
    "        tempe_month,\n",
    "        BROUND(AVG(averagetemperature),2) as averagetemperature,\n",
    "        BROUND(AVG(averagetemperatureuncertainty),2) as averagetemperatureuncertainty,\n",
    "        tempe_year,\n",
    "        dt_converted\n",
    "    FROM worldtempe_table\n",
    "    GROUP BY city, tempe_month, tempe_year, dt_converted\n",
    "\"\"\").createOrReplaceTempView('worldtempe_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------+-----------------------------+----------+------------+\n",
      "|       city|tempe_month|averagetemperature|averagetemperatureuncertainty|tempe_year|dt_converted|\n",
      "+-----------+-----------+------------------+-----------------------------+----------+------------+\n",
      "|ALBUQUERQUE|          4|              8.71|                         0.36|      1970|  1970-04-01|\n",
      "|  ALLENTOWN|          4|              8.72|                         0.18|      1984|  1984-04-01|\n",
      "|  ANCHORAGE|          4|             -1.29|                         0.43|      1987|  1987-04-01|\n",
      "+-----------+-----------+------------------+-----------------------------+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM worldtempe_table\n",
    "    WHERE tempe_month == 4\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+\n",
      "|i94port_valid_code|   i94port_city_name|i94port_state_code|\n",
      "+------------------+--------------------+------------------+\n",
      "|               ALC|               ALCAN|                AK|\n",
      "|               ANC|           ANCHORAGE|                AK|\n",
      "|               BAR|BAKER AAF - BAKER...|                AK|\n",
      "|               DAC|       DALTONS CACHE|                AK|\n",
      "|               PIZ|DEW STATION PT LA...|                AK|\n",
      "|               DTH|        DUTCH HARBOR|                AK|\n",
      "|               EGL|               EAGLE|                AK|\n",
      "|               FRB|           FAIRBANKS|                AK|\n",
      "|               HOM|               HOMER|                AK|\n",
      "|               HYD|               HYDER|                AK|\n",
      "|               JUN|              JUNEAU|                AK|\n",
      "|               5KE|           KETCHIKAN|                AK|\n",
      "|               KET|           KETCHIKAN|                AK|\n",
      "|               MOS|MOSES POINT INTER...|                AK|\n",
      "|               NIK|             NIKISKI|                AK|\n",
      "|               NOM|                 NOM|                AK|\n",
      "|               PKC|         POKER CREEK|                AK|\n",
      "|               ORI|      PORT LIONS SPB|                AK|\n",
      "|               SKA|             SKAGWAY|                AK|\n",
      "|               SNP|     ST. PAUL ISLAND|                AK|\n",
      "+------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94port_df = spark.read.options(inferSchema=\"true\", delimiter=\",\", header = \"true\").csv(\"i94port_staging\")\n",
    "i94port_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94port_valid_code: string (nullable = true)\n",
      " |-- i94port_city_name: string (nullable = true)\n",
      " |-- i94port_state_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94port_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94port_table\n",
    "i94port_df.createOrReplaceTempView('i94port_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|amount_i94port_rows|\n",
      "+-------------------+\n",
      "|                583|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_i94port_rows\n",
    "    FROM i94port_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+\n",
      "|i94port_valid_code|   i94port_city_name|i94port_state_code|\n",
      "+------------------+--------------------+------------------+\n",
      "|               ALC|               ALCAN|                AK|\n",
      "|               ANC|           ANCHORAGE|                AK|\n",
      "|               BAR|BAKER AAF - BAKER...|                AK|\n",
      "+------------------+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM i94port_table\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create dim and fact tables from staging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# month, year???\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            immi94.arrival_date as arrival_date\n",
    "        FROM i94immi_table as immi94\n",
    "        LEFT JOIN worldtempe_table as wt\n",
    "                ON wt.dt_converted = immi94.arrival_date\n",
    "            \"\"\").createOrReplaceTempView('dim_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            dim_datetime.arrival_date,\n",
    "            MONTH(dim_datetime.arrival_date) as arrival_month, \n",
    "            YEAR(dim_datetime.arrival_date) as arrival_year\n",
    "        FROM dim_datetime\n",
    "            \"\"\").createOrReplaceTempView('dim_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------------+\n",
      "|       arrival_date|arrival_month|arrival_year|\n",
      "+-------------------+-------------+------------+\n",
      "|2016-04-28 00:00:00|            4|        2016|\n",
      "|2016-04-28 00:00:00|            4|        2016|\n",
      "|2016-04-28 00:00:00|            4|        2016|\n",
      "+-------------------+-------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_datetime\n",
    "            \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            i94port_table.i94port_valid_code as port_code,\n",
    "            i94port_table.i94port_city_name as city_name, \n",
    "            i94port_table.i94port_state_code as state\n",
    "        FROM i94port_table\n",
    "            \"\"\").createOrReplaceTempView('dim_port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|port_code|           city_name|state|\n",
      "+---------+--------------------+-----+\n",
      "|      ALC|               ALCAN|   AK|\n",
      "|      ANC|           ANCHORAGE|   AK|\n",
      "|      BAR|BAKER AAF - BAKER...|   AK|\n",
      "+---------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_port\n",
    "            \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            immi94.cicid as immi_cicid,\n",
    "            ddate.arrival_date as immi_datetime_iso,\n",
    "            ddate.arrival_month as travel_month,\n",
    "            ddate.arrival_year as travel_year,\n",
    "            immi94.i94port as arr_port_code\n",
    "        FROM i94immi_table as immi94\n",
    "        JOIN dim_datetime as ddate\n",
    "            ON ddate.arrival_month = immi94.i94mon\n",
    "            \"\"\").createOrReplaceTempView('dim_immi_traveller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------+-----------+-------------+\n",
      "|immi_cicid|  immi_datetime_iso|travel_month|travel_year|arr_port_code|\n",
      "+----------+-------------------+------------+-----------+-------------+\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|          DAL|\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|          DAL|\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|          DAL|\n",
      "+----------+-------------------+------------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_immi_traveller\n",
    "            \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "# dim_port as dport\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            d_travel.immi_cicid as immi_cicid,\n",
    "            d_travel.immi_datetime_iso as immi_datetime_iso,\n",
    "            d_travel.travel_month as travel_month,\n",
    "            d_travel.travel_year as travel_year,\n",
    "            dport.city_name as travel_city,\n",
    "            d_travel.arr_port_code as arr_port_code\n",
    "        FROM dim_port as dport\n",
    "        JOIN dim_immi_traveller as d_travel\n",
    "            ON dport.port_code = d_travel.arr_port_code\n",
    "     \"\"\").createOrReplaceTempView('dim_immi_traveller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------+-----------+-----------+-------------+\n",
      "|immi_cicid|  immi_datetime_iso|travel_month|travel_year|travel_city|arr_port_code|\n",
      "+----------+-------------------+------------+-----------+-----------+-------------+\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|     DALLAS|          DAL|\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|     DALLAS|          DAL|\n",
      "| 5341351.0|2016-04-28 00:00:00|           4|       2016|     DALLAS|          DAL|\n",
      "+----------+-------------------+------------+-----------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_immi_traveller\n",
    "            \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "# dim_port as dport\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            ddate.arrival_date as collected_datetime,\n",
    "            ddate.arrival_month as tempe_month,\n",
    "            wt.averagetemperature as avg_tempe,\n",
    "            wt.averagetemperatureuncertainty as avg_uncertain_tempe,\n",
    "            wt.city as city_tempe_collect\n",
    "        FROM dim_datetime as ddate\n",
    "        LEFT JOIN worldtempe_table as wt\n",
    "            ON wt.tempe_month = ddate.arrival_month\n",
    "     \"\"\").createOrReplaceTempView('dim_us_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+---------+-------------------+------------------+\n",
      "| collected_datetime|tempe_month|avg_tempe|avg_uncertain_tempe|city_tempe_collect|\n",
      "+-------------------+-----------+---------+-------------------+------------------+\n",
      "|2016-04-28 00:00:00|          4|     9.02|               0.28|       WESTMINSTER|\n",
      "|2016-04-28 00:00:00|          4|    10.73|               0.32|  WEST VALLEY CITY|\n",
      "|2016-04-28 00:00:00|          4|     7.11|               0.28|  WEST VALLEY CITY|\n",
      "|2016-04-28 00:00:00|          4|     11.3|                0.4|       WEST JORDAN|\n",
      "|2016-04-28 00:00:00|          4|     11.2|               0.28|       WEST JORDAN|\n",
      "+-------------------+-----------+---------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_us_temperature\n",
    "     \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Load to fact_immi_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            d_travel.immi_cicid as traveller_cicid,\n",
    "            d_travel.arr_port_code as arr_port_code,\n",
    "            d_port.state as arr_state_code,\n",
    "            d_travel.travel_city as arr_city,\n",
    "            d_travel.travel_month as arr_month,\n",
    "            d_travel.travel_year as arr_year\n",
    "        FROM dim_immi_traveller as d_travel\n",
    "        JOIN dim_port as d_port\n",
    "            ON d_port.port_code = d_travel.arr_port_code\n",
    "     \"\"\").createOrReplaceTempView('fact_immi_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "|traveller_cicid|arr_port_code|arr_state_code|arr_city|arr_month|arr_year|\n",
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM fact_immi_weather\n",
    "     \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "|traveller_cicid|arr_port_code|arr_state_code|arr_city|arr_month|arr_year|\n",
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "|      5341351.0|          DAL|            TX|  DALLAS|        4|    2016|\n",
      "+---------------+-------------+--------------+--------+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            fact.traveller_cicid as traveller_cicid,\n",
    "            fact.arr_port_code as arr_port_code,\n",
    "            fact.arr_state_code as arr_state_code,\n",
    "            fact.arr_city as arr_city,\n",
    "            fact.arr_month as arr_month,\n",
    "            fact.arr_year as arr_year\n",
    "        FROM fact_immi_weather as fact\n",
    "     \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            fact.traveller_cicid as traveller_cicid,\n",
    "            fact.arr_port_code as arr_port_code,\n",
    "            fact.arr_state_code as arr_state_code,\n",
    "            fact.arr_city as arr_city,\n",
    "            d_tempe.avg_tempe as avg_tempe,\n",
    "            d_tempe.avg_uncertain_tempe as avg_uncertain_tempe,\n",
    "            fact.arr_month as arr_month,\n",
    "            fact.arr_year as arr_year\n",
    "        FROM fact_immi_weather as fact\n",
    "        JOIN dim_us_temperature as d_tempe\n",
    "            ON d_tempe.city_tempe_collect = fact.arr_city\n",
    "     \"\"\").createOrReplaceTempView('fact_immi_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM fact_immi_weather\n",
    "     \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f19dfd6b1cd7fd360d4f2c4802461aa893d068ea99183b3eab6718091575a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
