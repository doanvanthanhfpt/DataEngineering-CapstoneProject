{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here - Done\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import col, udf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['etl.cfg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('etl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data_source = config.get('DIR','INPUT_DIR')\n",
    "output_processed_data = config.get('DIR','OUTPUT_DIR')\n",
    "\n",
    "i94immi_dataset = config.get('DATA','I94_IMMI')\n",
    "worldtempe_dataset = config.get('DATA','WORLD_TEMPE')\n",
    "citydemo_dataset = config.get('DATA','CITY_DEMOGRAPHIC')\n",
    "airport_dataset = config.get('DATA','AIR_PORT')\n",
    "saslabel_dataset = config.get('DATA','SAS_LABEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session - Using for droduction only\n",
    "spark = SparkSession.builder\\\n",
    "            .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "            .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "            .enableHiveSupport()\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "func =  udf (lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Transform to dim_datetime tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Read out from staging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- I94 Immigration staging table: `i94immi_table`\n",
    "- World Temperature staging table: `worldtempe_table`\n",
    "- I94PORT staging table `i94port_table` from SAS_Labels_Description\n",
    "- Dim table of date that immigration happen `dim_datetime`\n",
    "- Dim table of airport that immigration allows `dim_port`\n",
    "- Dim table of immigration records `dim_immi_traveller`\n",
    "- Dim table of measure times `dim_us_temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|        dt|averagetemperature|averagetemperatureuncertainty|   city|dt_converted|      country|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|1960-02-01|             4.995|                        0.325|ABILENE|  1960-02-01|United States|\n",
      "|1960-03-01| 8.575000000000001|                        0.303|ABILENE|  1960-03-01|United States|\n",
      "|1960-04-01|            18.452|                        0.282|ABILENE|  1960-04-01|United States|\n",
      "|1960-05-01|            21.709|          0.28600000000000003|ABILENE|  1960-05-01|United States|\n",
      "|1960-06-01|            27.714|                        0.387|ABILENE|  1960-06-01|United States|\n",
      "|1960-07-01|            27.646|                        0.326|ABILENE|  1960-07-01|United States|\n",
      "|1960-08-01|            27.481|                        0.341|ABILENE|  1960-08-01|United States|\n",
      "|1960-09-01|            24.413|                        0.241|ABILENE|  1960-09-01|United States|\n",
      "|1960-10-01|18.929000000000002|          0.28600000000000003|ABILENE|  1960-10-01|United States|\n",
      "|1960-11-01|            12.531|                        0.235|ABILENE|  1960-11-01|United States|\n",
      "|1960-12-01|             4.114|                        0.214|ABILENE|  1960-12-01|United States|\n",
      "|1961-01-01|             3.827|                        0.337|ABILENE|  1961-01-01|United States|\n",
      "|1961-02-01|              7.63|                        0.349|ABILENE|  1961-02-01|United States|\n",
      "|1961-03-01|12.799000000000001|                        0.329|ABILENE|  1961-03-01|United States|\n",
      "|1961-04-01|            17.142|                        0.397|ABILENE|  1961-04-01|United States|\n",
      "|1961-05-01|            22.582|                        0.254|ABILENE|  1961-05-01|United States|\n",
      "|1961-06-01|             24.53|                        0.333|ABILENE|  1961-06-01|United States|\n",
      "|1961-07-01|            25.783|                         0.24|ABILENE|  1961-07-01|United States|\n",
      "|1961-08-01|26.052000000000003|                        0.205|ABILENE|  1961-08-01|United States|\n",
      "|1961-09-01|22.875999999999998|                        0.391|ABILENE|  1961-09-01|United States|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df = spark.read.csv(\"worldtempe_df_clean.csv\", header=True)\n",
    "worldtempe_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- averagetemperature: string (nullable = true)\n",
      " |-- averagetemperatureuncertainty: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- dt_converted: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>averagetemperature</th>\n",
       "      <th>averagetemperatureuncertainty</th>\n",
       "      <th>city</th>\n",
       "      <th>dt_converted</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>4.995</td>\n",
       "      <td>0.325</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-02-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>8.575000000000001</td>\n",
       "      <td>0.303</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-03-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>18.452</td>\n",
       "      <td>0.282</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-04-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>21.709</td>\n",
       "      <td>0.28600000000000003</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-06-01</td>\n",
       "      <td>27.714</td>\n",
       "      <td>0.387</td>\n",
       "      <td>ABILENE</td>\n",
       "      <td>1960-06-01</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt averagetemperature averagetemperatureuncertainty     city  \\\n",
       "0  1960-02-01              4.995                         0.325  ABILENE   \n",
       "1  1960-03-01  8.575000000000001                         0.303  ABILENE   \n",
       "2  1960-04-01             18.452                         0.282  ABILENE   \n",
       "3  1960-05-01             21.709           0.28600000000000003  ABILENE   \n",
       "4  1960-06-01             27.714                         0.387  ABILENE   \n",
       "\n",
       "  dt_converted        country  \n",
       "0   1960-02-01  United States  \n",
       "1   1960-03-01  United States  \n",
       "2   1960-04-01  United States  \n",
       "3   1960-05-01  United States  \n",
       "4   1960-06-01  United States  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt', 'string'),\n",
       " ('averagetemperature', 'string'),\n",
       " ('averagetemperatureuncertainty', 'string'),\n",
       " ('city', 'string'),\n",
       " ('dt_converted', 'string'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|        dt|averagetemperature|averagetemperatureuncertainty|   city|dt_converted|      country|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "|1960-02-01|             4.995|                        0.325|ABILENE|  1960-02-01|United States|\n",
      "|1960-03-01| 8.575000000000001|                        0.303|ABILENE|  1960-03-01|United States|\n",
      "+----------+------------------+-----------------------------+-------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worldtempe_df = worldtempe_df.withColumn('dt_converted', func(col('dt_converted')))\n",
    "worldtempe_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dt', 'string'),\n",
       " ('averagetemperature', 'string'),\n",
       " ('averagetemperatureuncertainty', 'string'),\n",
       " ('city', 'string'),\n",
       " ('dt_converted', 'date'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldtempe_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "worldtempe_df.createOrReplaceTempView('worldtempe_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|amount_worldtempe_rows|\n",
      "+----------------------+\n",
      "|                165508|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_worldtempe_rows\n",
    "    FROM worldtempe_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            dt_converted,\n",
    "            MONTH(worldtempe_table.dt_converted) as tempe_month,\n",
    "            YEAR(worldtempe_table.dt_converted) as tempe_year,\n",
    "            dt,\n",
    "            city,\n",
    "            averagetemperature,\n",
    "            averagetemperatureuncertainty\n",
    "        FROM worldtempe_table\n",
    "            \"\"\").createOrReplaceTempView('worldtempe_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|    cicid| i94yr|i94mon|       arrival_date|i94res|i94port|arrdate|i94addr|     departure_date|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "|5341351.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341352.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341353.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341354.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341355.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NV|2016-05-03 00:00:00|\n",
      "|5341356.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     NY|2016-05-08 00:00:00|\n",
      "|5341357.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-01 00:00:00|\n",
      "|5341358.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-02 00:00:00|\n",
      "|5341359.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    DAL|20572.0|     TX|2016-05-07 00:00:00|\n",
      "|5341367.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|   null|2016-04-30 00:00:00|\n",
      "|5341368.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|   null|2016-04-30 00:00:00|\n",
      "|5341371.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-05-13 00:00:00|\n",
      "|5341372.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-05-13 00:00:00|\n",
      "|5341373.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NJ|2016-06-01 00:00:00|\n",
      "|5341374.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341375.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341376.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341377.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-01 00:00:00|\n",
      "|5341378.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-02 00:00:00|\n",
      "|5341379.0|2016.0|   4.0|2016-04-28 00:00:00| 575.0|    NEW|20572.0|     NY|2016-05-02 00:00:00|\n",
      "+---------+------+------+-------------------+------+-------+-------+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df = spark.read.options(inferSchema=\"true\", delimiter=\",\", header = \"true\").csv(\"i94immi_df_clean\")\n",
    "i94immi_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- arrival_date: timestamp (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- departure_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94immi_df.createOrReplaceTempView('i94immi_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|amount_i94immi_rows|\n",
      "+-------------------+\n",
      "|            2465314|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_i94immi_rows\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+------------------+\n",
      "|i94port_valid_code|   i94port_city_name|i94port_state_code|\n",
      "+------------------+--------------------+------------------+\n",
      "|               ALC|               ALCAN|                AK|\n",
      "|               ANC|           ANCHORAGE|                AK|\n",
      "|               BAR|BAKER AAF - BAKER...|                AK|\n",
      "|               DAC|       DALTONS CACHE|                AK|\n",
      "|               PIZ|DEW STATION PT LA...|                AK|\n",
      "|               DTH|        DUTCH HARBOR|                AK|\n",
      "|               EGL|               EAGLE|                AK|\n",
      "|               FRB|           FAIRBANKS|                AK|\n",
      "|               HOM|               HOMER|                AK|\n",
      "|               HYD|               HYDER|                AK|\n",
      "|               JUN|              JUNEAU|                AK|\n",
      "|               5KE|           KETCHIKAN|                AK|\n",
      "|               KET|           KETCHIKAN|                AK|\n",
      "|               MOS|MOSES POINT INTER...|                AK|\n",
      "|               NIK|             NIKISKI|                AK|\n",
      "|               NOM|                 NOM|                AK|\n",
      "|               PKC|         POKER CREEK|                AK|\n",
      "|               ORI|      PORT LIONS SPB|                AK|\n",
      "|               SKA|             SKAGWAY|                AK|\n",
      "|               SNP|     ST. PAUL ISLAND|                AK|\n",
      "+------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94port_df = spark.read.options(inferSchema=\"true\", delimiter=\",\", header = \"true\").csv(\"i94port_staging\")\n",
    "i94port_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- i94port_valid_code: string (nullable = true)\n",
      " |-- i94port_city_name: string (nullable = true)\n",
      " |-- i94port_state_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94port_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94port_df.createOrReplaceTempView('i94port_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|amount_i94port_rows|\n",
      "+-------------------+\n",
      "|                583|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as amount_i94port_rows\n",
    "    FROM i94port_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create tables from staging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            immi94.departure_date as arrival_date\n",
    "        FROM i94immi_table as immi94\n",
    "        LEFT JOIN worldtempe_table as wt\n",
    "                ON wt.dt_converted = immi94.departure_date\n",
    "            \"\"\").createOrReplaceTempView('dim_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            dim_datetime.arrival_date,\n",
    "            MONTH(dim_datetime.arrival_date) as arrival_month, \n",
    "            YEAR(dim_datetime.arrival_date) as arrival_year\n",
    "        FROM dim_datetime\n",
    "            \"\"\").createOrReplaceTempView('dim_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------------+\n",
      "|       arrival_date|arrival_month|arrival_year|\n",
      "+-------------------+-------------+------------+\n",
      "|2016-05-03 00:00:00|            5|        2016|\n",
      "|2016-05-03 00:00:00|            5|        2016|\n",
      "|2016-05-03 00:00:00|            5|        2016|\n",
      "|2016-05-03 00:00:00|            5|        2016|\n",
      "|2016-05-03 00:00:00|            5|        2016|\n",
      "|2016-05-08 00:00:00|            5|        2016|\n",
      "|2016-05-01 00:00:00|            5|        2016|\n",
      "|2016-05-02 00:00:00|            5|        2016|\n",
      "|2016-05-07 00:00:00|            5|        2016|\n",
      "|2016-04-30 00:00:00|            4|        2016|\n",
      "|2016-04-30 00:00:00|            4|        2016|\n",
      "|2016-05-13 00:00:00|            5|        2016|\n",
      "|2016-05-13 00:00:00|            5|        2016|\n",
      "|2016-06-01 00:00:00|            6|        2016|\n",
      "|2016-05-01 00:00:00|            5|        2016|\n",
      "|2016-05-01 00:00:00|            5|        2016|\n",
      "|2016-05-01 00:00:00|            5|        2016|\n",
      "|2016-05-01 00:00:00|            5|        2016|\n",
      "|2016-05-02 00:00:00|            5|        2016|\n",
      "|2016-05-02 00:00:00|            5|        2016|\n",
      "+-------------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_datetime\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            i94port_table.i94port_valid_code as port_code,\n",
    "            i94port_table.i94port_city_name as city_name, \n",
    "            i94port_table.i94port_state_code as state\n",
    "        FROM i94port_table\n",
    "            \"\"\").createOrReplaceTempView('dim_port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|port_code|           city_name|state|\n",
      "+---------+--------------------+-----+\n",
      "|      ALC|               ALCAN|   AK|\n",
      "|      ANC|           ANCHORAGE|   AK|\n",
      "|      BAR|BAKER AAF - BAKER...|   AK|\n",
      "|      DAC|       DALTONS CACHE|   AK|\n",
      "|      PIZ|DEW STATION PT LA...|   AK|\n",
      "|      DTH|        DUTCH HARBOR|   AK|\n",
      "|      EGL|               EAGLE|   AK|\n",
      "|      FRB|           FAIRBANKS|   AK|\n",
      "|      HOM|               HOMER|   AK|\n",
      "|      HYD|               HYDER|   AK|\n",
      "|      JUN|              JUNEAU|   AK|\n",
      "|      5KE|           KETCHIKAN|   AK|\n",
      "|      KET|           KETCHIKAN|   AK|\n",
      "|      MOS|MOSES POINT INTER...|   AK|\n",
      "|      NIK|             NIKISKI|   AK|\n",
      "|      NOM|                 NOM|   AK|\n",
      "|      PKC|         POKER CREEK|   AK|\n",
      "|      ORI|      PORT LIONS SPB|   AK|\n",
      "|      SKA|             SKAGWAY|   AK|\n",
      "|      SNP|     ST. PAUL ISLAND|   AK|\n",
      "+---------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_port\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            immi94.cicid as immi_cicid,\n",
    "            ddate.arrival_date as immi_datetime_iso,\n",
    "            immi94.i94port as arr_port_code\n",
    "        FROM i94immi_table as immi94\n",
    "        JOIN dim_datetime as ddate\n",
    "            ON ddate.arrival_date = immi94.arrival_date\n",
    "            \"\"\").createOrReplaceTempView('dim_immi_traveller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------+\n",
      "|immi_cicid|  immi_datetime_iso|arr_port_code|\n",
      "+----------+-------------------+-------------+\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "+----------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_immi_traveller\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            immi94.cicid as immi_cicid,\n",
    "            ddate.arrival_date as immi_datetime_iso,\n",
    "            immi94.i94port as arr_port_code\n",
    "        FROM i94immi_table as immi94\n",
    "        JOIN dim_datetime as ddate\n",
    "            ON ddate.arrival_date = immi94.arrival_date\n",
    "            \"\"\").createOrReplaceTempView('dim_immi_traveller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            city|\n",
      "+----------------+\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|          DALLAS|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "|NEWARK/TETERBORO|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "spark.sql(\"\"\"\n",
    "        SELECT d_port.city_name as city\n",
    "        FROM dim_port as d_port\n",
    "        JOIN i94immi_table as immi94\n",
    "            ON immi94.i94port = d_port.port_code\n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------+\n",
      "|immi_cicid|  immi_datetime_iso|arr_port_code|\n",
      "+----------+-------------------+-------------+\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "| 1633969.0|2016-04-10 00:00:00|          CHI|\n",
      "+----------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_immi_traveller\n",
    "     \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----+\n",
      "|port_code|           city_name|state|\n",
      "+---------+--------------------+-----+\n",
      "|      ALC|               ALCAN|   AK|\n",
      "|      ANC|           ANCHORAGE|   AK|\n",
      "|      BAR|BAKER AAF - BAKER...|   AK|\n",
      "|      DAC|       DALTONS CACHE|   AK|\n",
      "|      PIZ|DEW STATION PT LA...|   AK|\n",
      "|      DTH|        DUTCH HARBOR|   AK|\n",
      "|      EGL|               EAGLE|   AK|\n",
      "|      FRB|           FAIRBANKS|   AK|\n",
      "|      HOM|               HOMER|   AK|\n",
      "|      HYD|               HYDER|   AK|\n",
      "|      JUN|              JUNEAU|   AK|\n",
      "|      5KE|           KETCHIKAN|   AK|\n",
      "|      KET|           KETCHIKAN|   AK|\n",
      "|      MOS|MOSES POINT INTER...|   AK|\n",
      "|      NIK|             NIKISKI|   AK|\n",
      "|      NOM|                 NOM|   AK|\n",
      "|      PKC|         POKER CREEK|   AK|\n",
      "|      ORI|      PORT LIONS SPB|   AK|\n",
      "|      SKA|             SKAGWAY|   AK|\n",
      "|      SNP|     ST. PAUL ISLAND|   AK|\n",
      "+---------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_port\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "# dim_port as dport\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            dport.city_name as travel_city,\n",
    "            d_travel.arr_port_code as arr_port_code,\n",
    "            d_travel.immi_datetime_iso as immi_datetime_iso,\n",
    "            d_travel.immi_cicid as immi_cicid\n",
    "        FROM dim_port as dport\n",
    "        JOIN dim_immi_traveller as d_travel\n",
    "            ON dport.port_code = d_travel.arr_port_code\n",
    "     \"\"\").createOrReplaceTempView('dim_immi_traveller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Crash program\n",
    "spark.sql(\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM dim_immi_traveller\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "====================================================================\n",
    "===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# i94immi_table as immi94\n",
    "# worldtempe_table as wt\n",
    "# i94port_table as port\n",
    "# dim_datetime as ddate\n",
    "# dim_port as dport\n",
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            ddate.arrival_date as collected_datetime,\n",
    "            ddate.arrival_month as tempe_month,\n",
    "            wt.averagetemperature as avg_tempe,\n",
    "            wt.city as city_tempe_collect\n",
    "        FROM dim_datetime as ddate\n",
    "        LEFT JOIN worldtempe_table as wt\n",
    "            ON wt.tempe_month = ddate.arrival_month\n",
    "     \"\"\").createOrReplaceTempView('dim_us_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM dim_us_temperature\n",
    "     \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            city_tempe_collect,\n",
    "            AVG(avg_tempe)\n",
    "        FROM dim_us_temperature\n",
    "        GROUP BY city_tempe_collect\n",
    "     \"\"\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f19dfd6b1cd7fd360d4f2c4802461aa893d068ea99183b3eab6718091575a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
