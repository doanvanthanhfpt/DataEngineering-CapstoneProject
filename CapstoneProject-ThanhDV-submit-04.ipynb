{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "##### Introduction\n",
    "\n",
    "A core responsibility of The National Travel and Tourism Office (NTTO) is to collect, analyze, and disseminate international travel and tourism statistics. \n",
    "\n",
    "NTTO's Board of Managers are charged with managing, improving, and expanding the system to fully account and report the impact of travel and tourism in the United States. The analysis results help to forcecast and operation, support make decision creates a positive climate for growth in travel and tourism by reducing institutional barriers to tourism, administers joint marketing efforts, provides official travel and tourism statistics, and coordinates efforts across federal agencies.\n",
    "\n",
    "##### Project Description\n",
    "\n",
    "In this project, some source datas will be use to do data modeling:\n",
    "* **I94 Immigration**: The source data for I94 immigration data is available in local disk in the format of sas7bdat. This data comes from US National Tourism and Trade Office. The data dictionary is also included in this project for reference. The actual source of the data is from https://travel.trade.gov/research/reports/i94/historical/2016.html. This data is already uploaded to the workspace.\n",
    "\n",
    "* **World Temperature Data**: This dataset came from Kaggle. This data is already uploaded to the workspace.\n",
    "\n",
    "* **Airport Code**: This is a simple table with airport codes. The source of this data is from https://datahub.io/core/airport-codes#data. It is highly recommended to use it for educational purpose only but not for commercial or any other purpose. This data is already uploaded to the workspace.\n",
    "\n",
    "* **U.S. City Demographic Data**: This data comes from OpenSoft link https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "* Other validation text files such as *I94Addr.txt*, *I94CIT_I94RES.txt*, *I94Mode.txt*, *I94Port.txt** and **I94Visa.txt* extracted from the *I94_SAS_Labels_Descriptions.SAS*.\n",
    "\n",
    "##### The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Scope the Project and Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scope "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make decision of project scope and the technical step solution we do data assessment on datasets:\n",
    "* I94 Immigration\n",
    "* World Temperature Data\n",
    "* U.S. City Demographic Data\n",
    "* Airport Code\n",
    "* Other reference *I94_SAS_Labels_Descriptions.SAS*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools will be used and import:\n",
    "- Spark\n",
    "- Python and its modules\n",
    "- Pandas\n",
    "- AWS Redshift cluster will be considered as an optional to run one or more ETL steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Describe and Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform dataset assessment by  take a look on: \n",
    "- Amount of records and data size.\n",
    "- Schema, data column structure.\n",
    "- Sample records and attributes. \n",
    "\n",
    "And the last, choose datasets will be using for data modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of datasets will be assessed:\n",
    "- `I94 Immigration`\n",
    "- `World Temperature Data`\n",
    "- `U.S. City Demographic Data`\n",
    "- `Airport Code`\n",
    "- `I94_SAS_Labels_Descriptions.SAS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python script to review the output of datasets assessment\n",
    "```code reference\n",
    "    Describe_and_Gather_Data-submit-02.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our expectations :\n",
    "- The relation between amount of travel immigration with weather duration of US regions.\n",
    "- The relation between amount of travel immigration with US airports.\n",
    "- The relation between amount of travel immigration with city demographics.\n",
    "- About immigration type statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset quality and validation issues recognition from gathering steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I94 Immigration dataset:\n",
    "    - `cicid`: Code for visitor origin country. Need to perform uniqueness verification. Have to review datatype. Check NULL values.\n",
    "    - `i94yr | i94mon`: Year, Month of immigration date. Have to review data type. Check NULL or NaN values.\n",
    "    - `i94cit | i94res`: Country of citizenship & Country of recidence. Have to validate these values with `I94_SAS_Labels_Descriptions.SAS`. Check NULL or Nan values.\n",
    "    - `i94port`: Code for destination immigration port of a specific USA city. Have to validate these values with **I94_SAS_Labels_Descriptions.SAS**. There are types of airport that do not allow immigration entry. Check NULL or Nan values.\n",
    "    - `arrdate | depdate`: Arrival date in the USA & Departure date from the USA. Have to review datatype. Check NULL values. Check the dependence between arrival date and departure date. \n",
    "    - `i94mode`: Code for immigration transportation mode. Have to validate these values with **I94_SAS_Labels_Descriptions.SAS**. There are methods of immigration transportation without airport gateway.\n",
    "    - `i94addr`: US state code. Have to validate these values with **I94_SAS_Labels_Descriptions.SAS**.\n",
    "    - `i94bir`: Age of Respondent in Years. Have to review data type. Check NULL or NaN values. We should scope passenger with birth year that keep use airport for their traveling next many year. The analysis will be usefull also.\n",
    "    - `i94visa`: Code for visa type corresponse to visiting reason. Have to validate these values with **I94_SAS_Labels_Descriptions.SAS**.\n",
    "    - count, tadfile, visapost, occup, entdepa, entdepd, entdepu, matflag, dtaddto, insnum: Useless. Do not use these columns.\n",
    "    - `biryear`: Immigrant year of birth. Have to review data type. Check NULL or NaN values. We should scope passenger with birth year that keep use airport for their traveling next many year. The analysis will be usefull also.\n",
    "    - `gender`: Immigrant sex. There are some un-common sex kind. No need these un-common values.\n",
    "    - `airline`: Airline used to arrive in U.S. Have to review data type. Check NULL or NaN values. Check for combination key.\n",
    "    - `admnum`: Admission Number. Have to review data type. Check NULL or NaN values.\n",
    "    - `fltno`: Flight number of Airline used to arrive in U.S. Have to review data type. Check NULL or NaN values.\n",
    "    - `visatype`: Class of admission legally admitting the non-immigrant to temporarily stay in U.S. Have to validate these values with **I94_SAS_Labels_Descriptions.SAS**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- World Temperature dataset\n",
    "    - `dt`: The creation time of temperature. Datatype must be converto datetime. Perform uniqueless verification.\n",
    "    - `AverageTemperature | AverageTemperatureUncertainty`: temperature value recognized. Column name as title style, have to lower this column name.\n",
    "    - `City | Country`: City of Country that the teperature recognized. Column name as title style, have to lower this column name.\n",
    "    - `Latitude | Longitude`: Geographical location in lat-long. Helpful for heatmap but these columns is useless in our project.\n",
    "    - Character case of column names mixed of upper, lower, whitespace. Have to lower case and replace whitespaces with '_'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Airport Code dataset\n",
    "    - `ident`: The airport identification code. Have to perform uniqueness verification. Check code naming format. Have to review datatype. Check NULL values.\n",
    "    - `type`: The airport type. There is confused airport type don't allow immigration traveling. Have to filter out allow immigration airport.\n",
    "    - `name`: The airport name. Have to mapping this column to city and country.\n",
    "    - `elevation_ft | continent | gps_code | iata_code | local_code | coordinates`: No need for our project.\n",
    "    - `iso_country | iso_region | municipality`: The country & state & city or town of the airport. Have to filter out list of this combination of these belong to US only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- U.S. City Demographic dataset\n",
    "    - `city | state | state_code`: Polulation of a city of a state. Have to check the uniqueless of this combination. This combination is primarykey also.\n",
    "    - `male_population | female_population | total_population`: Main population statistics include male, female and total.\n",
    "    - `median_age | number_of_veterans | foreign_born | average_household_size | race | count`: No need for our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other reference *I94_SAS_Labels_Descriptions.SAS*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parse *I94_SAS_Labels_Descriptions.SAS*. for validations on staging steps\n",
    "    ```code reference\n",
    "        Extract_I94_SAS_Labels_Descriptions_SAS-submit-02.ipynb\n",
    "    ```\n",
    "    - The outputs of this step:\n",
    "        - `i94_addr.csv`\n",
    "        - `i94_cit_and_res.csv`\n",
    "        - `i94_mode.csv`\n",
    "        - `i94_port.csv`\n",
    "        - `i94_visa.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning I94 Immigration dataset\n",
    "\n",
    "    ```code reference\n",
    "        unitTest-cleaning_staging_i94.ipynb\n",
    "    ```\n",
    "    The outputs of this step: `i94immi_df_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning World Temperature dataset\n",
    "\n",
    "    ```code reference\n",
    "        unitTest-cleaning_staging_world_tempe.ipynb\n",
    "    ```\n",
    "    The outputs of this step: `worldtempe_df_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning U.S. City Demographic dataset\n",
    "\n",
    "    ```code reference\n",
    "        unitTest-cleaning_staging_usdemo.ipynb\n",
    "    ```\n",
    "    The outputs of this step: `citydemo_df_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning Airport Code dataset\n",
    "\n",
    "    ```code reference\n",
    "        unitTest-cleaning_staging_airport.ipynb\n",
    "    ```\n",
    "    The outputs of this step: `airports_df_clean.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Define the Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Conceptual Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start schema diagram transformed\n",
    "- Start_schema_diagram here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fact table:\n",
    "- As expectation mention, we want to find out the relations between US immigration with either weather, immigration traffic and the arrival place (city).\n",
    "- The fact table `fact_us_immigration` should includes columns:\n",
    "    - `cicid`\n",
    "    - `cit_country`\n",
    "    - `res_country`\n",
    "    - `year_olds`\n",
    "    - `visa_type`\n",
    "    - `visa_type_des`\n",
    "    - `arr_city`\n",
    "    - `arr_state`\n",
    "    - `arr_date`\n",
    "    - `dep_date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dim_us_airports` contains informations like US port of entry code, city, state code and state name.\n",
    "    - `airport_ident` \n",
    "    - `airport_name`\n",
    "    - `airport_type`\n",
    "    - `state`\n",
    "    - `municipality`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dim_us_teperature` contains temperature records of US cities has been collect corresponse immigration data scope.\n",
    "    - `date`\n",
    "    - `city`\n",
    "    - `avg_tempe`\n",
    "    - `avg_uncertain_tempe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dim_demographics` contains median age and population informations about US port cities.\n",
    "    - `city`\n",
    "    - `state`\n",
    "    - `median`\n",
    "    - `male`\n",
    "    - `female`\n",
    "    - `total_population`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dim_datetime` contains date information like year, month, day, week of year and weekday.\n",
    "    - `year`\n",
    "    - `month`\n",
    "    - `week`\n",
    "    - `weekday`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Mapping Out Data Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline steps are described below:\n",
    "- Load raw dataset from source into Spark dataframe: df_spark_i94, df_spark_dem and df_spark_temp for one month.\n",
    "- Clean each Spark dataframe as decscibed in *Step 2 Cleaning steps* and write each cleaned dataframe into parquet as staging table: stage_i94_immigration, stage_cities_demographics and stage_uscities_temperatures.\n",
    "- Create and load dimension tables: dim_us_ports, dim_visa, dim_countries, dim_travelmode and dim_demographics.\n",
    "- Create and load fact table fact_i94_visits joining stage_i94_immigration and stage_uscities_temperatures.\n",
    "- Create and load dimension tables and dim_date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Run Pipelines to Model the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Data Quality Checks\n",
    "\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    "\n",
    "* Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    "* Unit tests for the scripts to ensure they are doing the right thing\n",
    "* Source/Count checks to ensure completeness\n",
    "\n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension table will contain events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second dimension table will contain city temperature data. The columns below will be extracted from the temperature dataframe:\n",
    "* i94port = 3 character code of destination city (mapped from immigration data during cleanup step)\n",
    "* AverageTemperature = average temperature\n",
    "* City = city name\n",
    "* Country = country name\n",
    "* Latitude= latitude\n",
    "* Longitude = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact table will contain information from the I94 immigration data joined with the city temperature data on i94port:\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "* AverageTemperature = average temperature of destination city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    * Spark was chosen since it can easily handle multiple file formats (including SAS) containing large amounts of data. \n",
    "    * Spark SQL was chosen to process the large input files into dataframes and manipulated via standard SQL join operations to form additional tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Propose how often the data should be updated and why.\n",
    "    * The data should be updated monthly in conjunction with the current raw file format.\n",
    "    * Case 2\n",
    "    * Case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a description of how you would approach the problem differently under the following scenarios:\n",
    "    * The data was increased by 100x.\n",
    "    * If the data was increased by 100x, we would no longer process the data as a single batch job. We could perhaps do incremental updates using a tool such as Uber's Hudi. We could also consider moving Spark to cluster mode using a cluster manager such as Yarn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    * If the data needs to populate a dashboard daily to meet an SLA then we could use a scheduling tool such as Airflow to run the ETL pipeline overnight.\n",
    "    * Others solution ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The database needed to be accessed by 100+ people.\n",
    "    * If the database needed to be accessed by 100+ people, we could consider publishing the parquet files to HDFS and giving read access to users that need it. \n",
    "    * If the users want to run SQL queries on the raw data, we could consider publishing to HDFS using a tool such as Impala."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.test_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "af440d615888d659e90fddc0bb1ee33d8fb1bc777d369b970824ddfe4cd12e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
