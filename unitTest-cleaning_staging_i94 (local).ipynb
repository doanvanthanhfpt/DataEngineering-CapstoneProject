{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here - Done\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "import re\n",
    "import configparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('etl.cfg')\n",
    "\n",
    "input_data_source = config.get('DIR','INPUT_DIR')\n",
    "output_processed_data = config.get('DIR','OUTPUT_DIR')\n",
    "\n",
    "i94immi_dataset = config.get('DATA','I94_IMMI')\n",
    "worldtempe_dataset = config.get('DATA','WORLD_TEMPE')\n",
    "citydemo_dataset = config.get('DATA','CITY_DEMOGRAPHIC')\n",
    "airport_dataset = config.get('DATA','AIR_PORT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## I94 Immigration data cleaning and staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For i94 immigration format, we use spark.sql to cleaning and staging this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session - Using for droduction only\n",
    "spark = SparkSession.builder\\\n",
    "            .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "            .config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "            .enableHiveSupport()\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DV:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d6d3b780d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94immi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o82.load.\n: java.lang.NoClassDefFoundError: scala/Product$class\r\n\tat com.github.saurfang.sas.spark.SasRelation.<init>(SasRelation.scala:48)\r\n\tat com.github.saurfang.sas.spark.SasRelation$.apply(SasRelation.scala:42)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:50)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:39)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:27)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Using for SAS format production\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# i94immi_dataset = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# i94immi_df = spark.read.format('com.github.saurfang.sas.spark').load(i94immi_dataset)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39m# Using for local development\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# i94immi_dataset = 'immigration_data_sample.csv'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m i94immi_dataset \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mi94_apr16_sub.sas7bdat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m i94immi_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mformat(\u001b[39m'\u001b[39;49m\u001b[39mcom.github.saurfang.sas.spark\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mload(i94immi_dataset)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\pyspark\\sql\\readwriter.py:177\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mload(path))\n\u001b[0;32m    178\u001b[0m \u001b[39melif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o82.load.\n: java.lang.NoClassDefFoundError: scala/Product$class\r\n\tat com.github.saurfang.sas.spark.SasRelation.<init>(SasRelation.scala:48)\r\n\tat com.github.saurfang.sas.spark.SasRelation$.apply(SasRelation.scala:42)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:50)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:39)\r\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:27)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "# Using for SAS format production\n",
    "# i94immi_dataset = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "# i94immi_df = spark.read.format('com.github.saurfang.sas.spark').load(i94immi_dataset)\n",
    "\n",
    "# Using for local development\n",
    "# i94immi_dataset = 'immigration_data_sample.csv'\n",
    "i94immi_dataset = 'i94_apr16_sub.sas7bdat'\n",
    "i94immi_df = spark.read.format('com.github.saurfang.sas.spark').load(i94immi_dataset)\n",
    "# i94immi_df = spark.read.options(header='True',inferSchema='True',delimiter=',').csv(i94immi_dataset)\n",
    "# i94immi_df = pd.read_csv(i94immi_dataset,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94immi_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|    _c0|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|2027561|4084316.0|2016.0|   4.0| 209.0| 209.0|    HHW|20566.0|    1.0|     HI|20573.0|  61.0|    2.0|  1.0|20160422|    null| null|      G|      O|   null|      M| 1955.0|07202016|     F|  null|     JL|5.6582674633E10|00782|      WT|\n",
      "|2171295|4422636.0|2016.0|   4.0| 582.0| 582.0|    MCA|20567.0|    1.0|     TX|20568.0|  26.0|    2.0|  1.0|20160423|     MTR| null|      G|      R|   null|      M| 1990.0|10222016|     M|  null|    *GA| 9.436199593E10|XBLNG|      B2|\n",
      "| 589494|1195600.0|2016.0|   4.0| 148.0| 112.0|    OGG|20551.0|    1.0|     FL|20571.0|  76.0|    2.0|  1.0|20160407|    null| null|      G|      O|   null|      M| 1940.0|07052016|     M|  null|     LH|5.5780468433E10|00464|      WT|\n",
      "|2631158|5291768.0|2016.0|   4.0| 297.0| 297.0|    LOS|20572.0|    1.0|     CA|20581.0|  25.0|    2.0|  1.0|20160428|     DOH| null|      G|      O|   null|      M| 1991.0|10272016|     M|  null|     QR| 9.478969603E10|00739|      B2|\n",
      "|3032257| 985523.0|2016.0|   4.0| 111.0| 111.0|    CHM|20550.0|    3.0|     NY|20553.0|  19.0|    2.0|  1.0|20160406|    null| null|      Z|      K|   null|      M| 1997.0|07042016|     F|  null|   null|4.2322572633E10| LAND|      WT|\n",
      "| 721257|1481650.0|2016.0|   4.0| 577.0| 577.0|    ATL|20552.0|    1.0|     GA|20606.0|  51.0|    2.0|  1.0|20160408|    null| null|      T|      N|   null|      M| 1965.0|10072016|     M|  null|     DL|   7.36852585E8|  910|      B2|\n",
      "|1072780|2197173.0|2016.0|   4.0| 245.0| 245.0|    SFR|20556.0|    1.0|     CA|20635.0|  48.0|    2.0|  1.0|20160412|    null| null|      T|      O|   null|      M| 1968.0|10112016|     F|  null|     CX|   7.86312185E8|  870|      B2|\n",
      "| 112205| 232708.0|2016.0|   4.0| 113.0| 135.0|    NYC|20546.0|    1.0|     NY|20554.0|  33.0|    2.0|  1.0|20160402|    null| null|      G|      O|   null|      M| 1983.0|06302016|     F|  null|     BA|5.5474485033E10|00117|      WT|\n",
      "|2577162|5227851.0|2016.0|   4.0| 131.0| 131.0|    CHI|20572.0|    1.0|     IL|20575.0|  39.0|    2.0|  1.0|20160428|    null| null|      O|      O|   null|      M| 1977.0|07262016|  null|  null|     LX|5.9413424733E10|00008|      WT|\n",
      "|  10930|  13213.0|2016.0|   4.0| 116.0| 116.0|    LOS|20545.0|    1.0|     CA|20553.0|  35.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1981.0|06292016|  null|  null|     AA|5.5449792933E10|00109|      WT|\n",
      "| 617174|1230572.0|2016.0|   4.0| 438.0| 438.0|    LOS|20551.0|    1.0|     CA|20565.0|   4.0|    2.0|  1.0|20160407|    null| null|      G|      O|   null|      M| 2012.0|07052016|     F|  null|     QF|5.5743814633E10|00015|      WT|\n",
      "|2497156|5056736.0|2016.0|   4.0| 209.0| 209.0|    PHI|20571.0|    1.0|     HI|20575.0|  72.0|    2.0|  1.0|20160427|    null| null|      G|      O|   null|      M| 1944.0|07252016|     M|  null|     DL|5.9336618033E10|00598|      WT|\n",
      "|1339656|2711583.0|2016.0|   4.0| 148.0| 112.0|    FTL|20559.0|    2.0|   null|20565.0|  54.0|    2.0|  1.0|20160415|    null| null|      G|      O|   null|      M| 1962.0|07132016|     F|  null|    VES|5.6175860733E10|93724|      WT|\n",
      "|2430322|4916639.0|2016.0|   4.0| 260.0| 260.0|    LOS|20570.0|    1.0|     CA|20581.0|  62.0|    2.0|  1.0|20160426|     MNL| null|      G|      O|   null|      M| 1954.0|10252016|     F|  null|     EK| 9.461277103E10|00215|      B2|\n",
      "| 682005|1387607.0|2016.0|   4.0| 148.0| 112.0|    BOS|20552.0|    1.0|     MA|20560.0|  34.0|    2.0|  1.0|20160408|    null| null|      G|      K|   null|      M| 1982.0|07062016|     F|  null|     AF|5.5833387633E10|00338|      WT|\n",
      "|2938436|5960799.0|2016.0|   4.0| 245.0| 245.0|    SAI|20545.0|    1.0|   null|20550.0|  30.0|    2.0|  1.0|20160615|    null| null|      P|      D|   null|      M| 1986.0|04132016|     M|  3882|     MU|4.4162582033E10|00763|      CP|\n",
      "| 530804|1056530.0|2016.0|   4.0| 512.0| 512.0|    NAS|20550.0|    1.0|     GA|20552.0|  21.0|    2.0|  1.0|20160406|     NSS| null|      G|      O|   null|      M| 1995.0|10052016|     F|  null|     DL| 9.285800163E10|00554|      B2|\n",
      "|1187149|2466971.0|2016.0|   4.0| 689.0| 689.0|    FTL|20557.0|    1.0|     FL|20569.0|  43.0|    2.0|  1.0|20160413|    null| null|      O|      O|   null|      M| 1973.0|10122016|  null|  null|     AD| 9.338490163E10|08704|      B2|\n",
      "|2283033|4668286.0|2016.0|   4.0| 746.0| 158.0|    SEA|20568.0|    1.0|     NV|20571.0|  46.0|    2.0|  1.0|20160424|     MOS| null|      G|      O|   null|      M| 1970.0|10232016|     M|  null|     DL| 9.443560053E10|00143|      B2|\n",
      "|1262082|2556646.0|2016.0|   4.0| 260.0| 260.0|    FTL|20558.0|    1.0|     CA|20596.0|  14.0|    2.0|  1.0|20160414|     MNL| null|      G|      O|   null|      M| 2002.0|10132016|     M|  null|     OZ| 9.353684553E10|00204|      B2|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Create a sql table view of i94 immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94immi_df.createOrReplaceTempView('i94immi_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Choose Primarykey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "If distinct result of '**cicid**' the same to record amount of dataset. We can use **'cicid'** as primarykey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|                 1000|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT (DISTINCT cicid)\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning Arrival date and Departure date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We verify the logic of data, Departure date must be greater or equal Arrival date because:\n",
    "- Columns **'arrdate'** displays the arrival date in the USA \n",
    "- Column **'depdate'** as departure date from the USA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We count amount of records with Departure date <= Arrival date. These are un-makesence data will be droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM i94immi_table\n",
    "    WHERE arrdate >= depdate\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Show samples of un-makesence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|arrdate|depdate|\n",
      "+-------+-------+\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT arrdate, depdate\n",
    "    FROM i94immi_table\n",
    "    WHERE arrdate >= depdate\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We drop un-makesence logic values from i94immi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM i94immi_table\n",
    "    WHERE arrdate <= depdate\n",
    "\"\"\").createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Verify cleaned arrdate and depdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     951|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|    _c0|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|2027561|4084316.0|2016.0|   4.0| 209.0| 209.0|    HHW|20566.0|    1.0|     HI|20573.0|  61.0|    2.0|  1.0|20160422|    null| null|      G|      O|   null|      M| 1955.0|07202016|     F|  null|     JL|5.6582674633E10|00782|      WT|\n",
      "|2171295|4422636.0|2016.0|   4.0| 582.0| 582.0|    MCA|20567.0|    1.0|     TX|20568.0|  26.0|    2.0|  1.0|20160423|     MTR| null|      G|      R|   null|      M| 1990.0|10222016|     M|  null|    *GA| 9.436199593E10|XBLNG|      B2|\n",
      "| 589494|1195600.0|2016.0|   4.0| 148.0| 112.0|    OGG|20551.0|    1.0|     FL|20571.0|  76.0|    2.0|  1.0|20160407|    null| null|      G|      O|   null|      M| 1940.0|07052016|     M|  null|     LH|5.5780468433E10|00464|      WT|\n",
      "|2631158|5291768.0|2016.0|   4.0| 297.0| 297.0|    LOS|20572.0|    1.0|     CA|20581.0|  25.0|    2.0|  1.0|20160428|     DOH| null|      G|      O|   null|      M| 1991.0|10272016|     M|  null|     QR| 9.478969603E10|00739|      B2|\n",
      "|3032257| 985523.0|2016.0|   4.0| 111.0| 111.0|    CHM|20550.0|    3.0|     NY|20553.0|  19.0|    2.0|  1.0|20160406|    null| null|      Z|      K|   null|      M| 1997.0|07042016|     F|  null|   null|4.2322572633E10| LAND|      WT|\n",
      "| 721257|1481650.0|2016.0|   4.0| 577.0| 577.0|    ATL|20552.0|    1.0|     GA|20606.0|  51.0|    2.0|  1.0|20160408|    null| null|      T|      N|   null|      M| 1965.0|10072016|     M|  null|     DL|   7.36852585E8|  910|      B2|\n",
      "|1072780|2197173.0|2016.0|   4.0| 245.0| 245.0|    SFR|20556.0|    1.0|     CA|20635.0|  48.0|    2.0|  1.0|20160412|    null| null|      T|      O|   null|      M| 1968.0|10112016|     F|  null|     CX|   7.86312185E8|  870|      B2|\n",
      "| 112205| 232708.0|2016.0|   4.0| 113.0| 135.0|    NYC|20546.0|    1.0|     NY|20554.0|  33.0|    2.0|  1.0|20160402|    null| null|      G|      O|   null|      M| 1983.0|06302016|     F|  null|     BA|5.5474485033E10|00117|      WT|\n",
      "|2577162|5227851.0|2016.0|   4.0| 131.0| 131.0|    CHI|20572.0|    1.0|     IL|20575.0|  39.0|    2.0|  1.0|20160428|    null| null|      O|      O|   null|      M| 1977.0|07262016|  null|  null|     LX|5.9413424733E10|00008|      WT|\n",
      "|  10930|  13213.0|2016.0|   4.0| 116.0| 116.0|    LOS|20545.0|    1.0|     CA|20553.0|  35.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1981.0|06292016|  null|  null|     AA|5.5449792933E10|00109|      WT|\n",
      "| 617174|1230572.0|2016.0|   4.0| 438.0| 438.0|    LOS|20551.0|    1.0|     CA|20565.0|   4.0|    2.0|  1.0|20160407|    null| null|      G|      O|   null|      M| 2012.0|07052016|     F|  null|     QF|5.5743814633E10|00015|      WT|\n",
      "|2497156|5056736.0|2016.0|   4.0| 209.0| 209.0|    PHI|20571.0|    1.0|     HI|20575.0|  72.0|    2.0|  1.0|20160427|    null| null|      G|      O|   null|      M| 1944.0|07252016|     M|  null|     DL|5.9336618033E10|00598|      WT|\n",
      "|1339656|2711583.0|2016.0|   4.0| 148.0| 112.0|    FTL|20559.0|    2.0|   null|20565.0|  54.0|    2.0|  1.0|20160415|    null| null|      G|      O|   null|      M| 1962.0|07132016|     F|  null|    VES|5.6175860733E10|93724|      WT|\n",
      "|2430322|4916639.0|2016.0|   4.0| 260.0| 260.0|    LOS|20570.0|    1.0|     CA|20581.0|  62.0|    2.0|  1.0|20160426|     MNL| null|      G|      O|   null|      M| 1954.0|10252016|     F|  null|     EK| 9.461277103E10|00215|      B2|\n",
      "| 682005|1387607.0|2016.0|   4.0| 148.0| 112.0|    BOS|20552.0|    1.0|     MA|20560.0|  34.0|    2.0|  1.0|20160408|    null| null|      G|      K|   null|      M| 1982.0|07062016|     F|  null|     AF|5.5833387633E10|00338|      WT|\n",
      "|2938436|5960799.0|2016.0|   4.0| 245.0| 245.0|    SAI|20545.0|    1.0|   null|20550.0|  30.0|    2.0|  1.0|20160615|    null| null|      P|      D|   null|      M| 1986.0|04132016|     M|  3882|     MU|4.4162582033E10|00763|      CP|\n",
      "| 530804|1056530.0|2016.0|   4.0| 512.0| 512.0|    NAS|20550.0|    1.0|     GA|20552.0|  21.0|    2.0|  1.0|20160406|     NSS| null|      G|      O|   null|      M| 1995.0|10052016|     F|  null|     DL| 9.285800163E10|00554|      B2|\n",
      "|1187149|2466971.0|2016.0|   4.0| 689.0| 689.0|    FTL|20557.0|    1.0|     FL|20569.0|  43.0|    2.0|  1.0|20160413|    null| null|      O|      O|   null|      M| 1973.0|10122016|  null|  null|     AD| 9.338490163E10|08704|      B2|\n",
      "|2283033|4668286.0|2016.0|   4.0| 746.0| 158.0|    SEA|20568.0|    1.0|     NV|20571.0|  46.0|    2.0|  1.0|20160424|     MOS| null|      G|      O|   null|      M| 1970.0|10232016|     M|  null|     DL| 9.443560053E10|00143|      B2|\n",
      "|1262082|2556646.0|2016.0|   4.0| 260.0| 260.0|    FTL|20558.0|    1.0|     CA|20596.0|  14.0|    2.0|  1.0|20160414|     MNL| null|      G|      O|   null|      M| 2002.0|10132016|     M|  null|     OZ| 9.353684553E10|00204|      B2|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94immi_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We add column **'arrival_date'** from **'arrdate'** base on SAS correspond timestone *1960-01-01*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'date_add(to_date('1960-01-01'), i94immi_table.arrdate)' due to data type mismatch: argument 2 requires (int or smallint or tinyint) type, however, 'i94immi_table.arrdate' is of double type.; line 2 pos 14;\n'Project [_c0#92, cicid#93, i94yr#94, i94mon#95, i94cit#96, i94res#97, i94port#98, arrdate#99, i94mode#100, i94addr#101, depdate#102, i94bir#103, i94visa#104, count#105, dtadfile#106, visapost#107, occup#108, entdepa#109, entdepd#110, entdepu#111, matflag#112, biryear#113, dtaddto#114, gender#115, ... 6 more fields]\n+- SubqueryAlias i94immi_table\n   +- View (`i94immi_table`, [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,insnum#116,airline#117,admnum#118,fltno#119,visatype#120])\n      +- Project [_c0#92, cicid#93, i94yr#94, i94mon#95, i94cit#96, i94res#97, i94port#98, arrdate#99, i94mode#100, i94addr#101, depdate#102, i94bir#103, i94visa#104, count#105, dtadfile#106, visapost#107, occup#108, entdepa#109, entdepd#110, entdepu#111, matflag#112, biryear#113, dtaddto#114, gender#115, ... 5 more fields]\n         +- Filter (arrdate#99 <= depdate#102)\n            +- SubqueryAlias i94immi_table\n               +- View (`i94immi_table`, [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,insnum#116,airline#117,admnum#118,fltno#119,visatype#120])\n                  +- Relation [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,... 5 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_date \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49msql(\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      2\u001b[0m \u001b[39m    SELECT *, date_add(to_date(\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m1960-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m), arrdate) AS arrival_date \u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[39m    FROM i94immi_table\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\pyspark\\sql\\session.py:1034\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[1;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     sqlQuery \u001b[39m=\u001b[39m formatter\u001b[39m.\u001b[39mformat(sqlQuery, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1033\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1034\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsparkSession\u001b[39m.\u001b[39;49msql(sqlQuery), \u001b[39mself\u001b[39m)\n\u001b[0;32m   1035\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(kwargs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\project5\\lib\\site-packages\\pyspark\\sql\\utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve 'date_add(to_date('1960-01-01'), i94immi_table.arrdate)' due to data type mismatch: argument 2 requires (int or smallint or tinyint) type, however, 'i94immi_table.arrdate' is of double type.; line 2 pos 14;\n'Project [_c0#92, cicid#93, i94yr#94, i94mon#95, i94cit#96, i94res#97, i94port#98, arrdate#99, i94mode#100, i94addr#101, depdate#102, i94bir#103, i94visa#104, count#105, dtadfile#106, visapost#107, occup#108, entdepa#109, entdepd#110, entdepu#111, matflag#112, biryear#113, dtaddto#114, gender#115, ... 6 more fields]\n+- SubqueryAlias i94immi_table\n   +- View (`i94immi_table`, [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,insnum#116,airline#117,admnum#118,fltno#119,visatype#120])\n      +- Project [_c0#92, cicid#93, i94yr#94, i94mon#95, i94cit#96, i94res#97, i94port#98, arrdate#99, i94mode#100, i94addr#101, depdate#102, i94bir#103, i94visa#104, count#105, dtadfile#106, visapost#107, occup#108, entdepa#109, entdepd#110, entdepu#111, matflag#112, biryear#113, dtaddto#114, gender#115, ... 5 more fields]\n         +- Filter (arrdate#99 <= depdate#102)\n            +- SubqueryAlias i94immi_table\n               +- View (`i94immi_table`, [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,insnum#116,airline#117,admnum#118,fltno#119,visatype#120])\n                  +- Relation [_c0#92,cicid#93,i94yr#94,i94mon#95,i94cit#96,i94res#97,i94port#98,arrdate#99,i94mode#100,i94addr#101,depdate#102,i94bir#103,i94visa#104,count#105,dtadfile#106,visapost#107,occup#108,entdepa#109,entdepd#110,entdepu#111,matflag#112,biryear#113,dtaddto#114,gender#115,... 5 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "df_date = spark.sql(\"\"\"\n",
    "    SELECT *, date_add(to_date('1960-01-01'), arrdate) AS arrival_date \n",
    "    FROM i94immi_table\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_date.createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(arrival_date)|\n",
      "+-------------------+\n",
      "|            2953481|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(arrival_date)\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "And then add column **'departure_date'** column from **'depdate'** base on SAS correspond timestone *1960-01-01*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT *, CASE \n",
    "                        WHEN depdate >= arrdate THEN date_add(to_date('1960-01-01'), depdate)\n",
    "                        WHEN depdate IS NULL THEN NULL\n",
    "                        ELSE 'N/A' END AS departure_date \n",
    "                FROM i94immi_table\n",
    "            \"\"\").createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Verify column **'departure_date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(departure_date)|\n",
      "+---------------------+\n",
      "|              2953481|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(departure_date)\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Count distinct **'arrival_date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|min_arrival_date|max_arrival_date|\n",
      "+----------------+----------------+\n",
      "|      2016-04-01|      2016-04-30|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT MIN(arrival_date) as min_arrival_date, MAX(arrival_date) as max_arrival_date\n",
    "            FROM i94immi_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|distinct_arrival_date|\n",
      "+---------------------+\n",
      "|                   30|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT COUNT (DISTINCT arrival_date) as distinct_arrival_date\n",
    "            FROM i94immi_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Count distinct **'departure_date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|min_departure_date|max_departure_date|\n",
      "+------------------+------------------+\n",
      "|        2016-04-02|        2084-05-16|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT MIN(departure_date) as min_departure_date, MAX(departure_date) as max_departure_date\n",
    "            FROM i94immi_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|distinct_departure_date|\n",
      "+-----------------------+\n",
      "|                    174|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT COUNT (DISTINCT departure_date) as distinct_departure_date\n",
    "            FROM i94immi_table\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Count distinct date between **'arrival_date'** and **'departure_date'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|distinct_date_between|\n",
      "+---------------------+\n",
      "|                   29|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT COUNT(DISTINCT departure_date) as distinct_date_between\n",
    "            FROM i94immi_table \n",
    "            WHERE departure_date IN (SELECT DISTINCT arrival_date \n",
    "                                    FROM i94immi_table\n",
    "                                ) \n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Just one missing value (29/30) --> our dim_date tables will include **'arrival_date'** and **'departure_date'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Find any NaN or Null values on 'departure_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) FROM i94immi_table WHERE departure_date = 'N/A'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(*) FROM i94immi_table WHERE departure_date = 'NULL'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Verify again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2953481|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We check the column **'i94port'** and note value length of this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|i94port|\n",
      "+-------+\n",
      "|    WAS|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    TOR|\n",
      "|    BOS|\n",
      "|    ATL|\n",
      "|    ATL|\n",
      "|    ATL|\n",
      "|    ATL|\n",
      "|    HOU|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    NYC|\n",
      "|    MIA|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT i94port\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) \n",
    "    FROM i94immi_table \n",
    "    WHERE i94port == 'NaN'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) \n",
    "    FROM i94immi_table \n",
    "    WHERE i94port is NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Values length of column **'i94port'** is 3 charaters, this length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning i94mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next, we take a look on arival mode as column **i94mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|i94mode|count(1)|\n",
      "+-------+--------+\n",
      "|   null|     238|\n",
      "|    1.0| 2871184|\n",
      "|    3.0|   61572|\n",
      "|    2.0|   17970|\n",
      "|    9.0|    2517|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT i94mode, count(*)\n",
    "    FROM i94immi_table\n",
    "    GROUP BY i94mode\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "From I94_SAS_Labels_Descriptions_SAS we extracted **i94_mode.csv** includes info:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "{'1': 'Air', '2': 'Sea', '3': 'Land', '9': 'Not reported'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We keep air arrival only (**i94mode=1**), drop any arrival values else (null,, 2, 3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM i94immi_table\n",
    "    WHERE i94mode == 1.0\n",
    "\"\"\").createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Verify our table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2871184|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as number_of_records\n",
    "    FROM i94immi_table\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning i94visa, visatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "From **SAS_Labels**, we extracted visatype validation as **i94_visa.csv**. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "{'1': 'Business', '2': 'Pleasure', '3': 'Student'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This step, we mapping **i94visa** numbers to **visatype** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT *, CASE \n",
    "                    WHEN i94visa = 1.0 THEN 'Business' \n",
    "                    WHEN i94visa = 2.0 THEN 'Pleasure'\n",
    "                    WHEN i94visa = 3.0 THEN 'Student'\n",
    "                    ELSE 'N/A' END AS visa_type\n",
    "        FROM i94immi_table\n",
    "    \"\"\").createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We category **visatype** grouping by **visa_type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+\n",
      "|visa_type|visatype|count(1)|\n",
      "+---------+--------+--------+\n",
      "| Business|      B1|  201741|\n",
      "| Business|      E1|    3027|\n",
      "| Business|      E2|   15157|\n",
      "| Business|     GMB|     132|\n",
      "| Business|       I|    2931|\n",
      "| Business|      I1|     211|\n",
      "| Business|      WB|  277414|\n",
      "| Pleasure|      B2| 1008434|\n",
      "| Pleasure|      CP|   11891|\n",
      "| Pleasure|     CPL|       8|\n",
      "| Pleasure|     GMT|   79777|\n",
      "| Pleasure|     SBP|       2|\n",
      "| Pleasure|      WT| 1243531|\n",
      "|  Student|      F1|   24599|\n",
      "|  Student|      F2|    1622|\n",
      "|  Student|      M1|     679|\n",
      "|  Student|      M2|      28|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT visa_type as visa_type, visatype as visatype_code, count(*) as count_by_visa_category\n",
    "        FROM i94immi_table\n",
    "        GROUP BY visa_type, visatype\n",
    "        ORDER BY visa_type, visatype\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Find any NaN or Null values on 'visatype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_null_of_visatype\n",
    "    FROM i94immi_table \n",
    "    WHERE visatype is NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_missing_values\n",
    "    FROM i94immi_table \n",
    "    WHERE visatype == 'NaN'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning i94bir and biryear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check check whether value is NULL or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      46|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_NULL_values\n",
    "    FROM i94immi_table \n",
    "    WHERE i94bir is NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      46|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_NULL_values\n",
    "    FROM i94immi_table \n",
    "    WHERE biryear is NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max_biryear|min_biryear|\n",
      "+-----------+-----------+\n",
      "|     2016.0|     1916.0|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT MAX(biryear) as max_biryear, MIN(biryear) as min_biryear\n",
    "    FROM i94immi_table \n",
    "    WHERE biryear IS NOT NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Take a look on travel velocity for 90 years old and older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|biryear|count(1)|\n",
      "+-------+--------+\n",
      "| 1916.0|       8|\n",
      "| 1917.0|      16|\n",
      "| 1918.0|      21|\n",
      "| 1919.0|      36|\n",
      "| 1920.0|      34|\n",
      "| 1921.0|      69|\n",
      "| 1922.0|      89|\n",
      "| 1923.0|     155|\n",
      "| 1924.0|     209|\n",
      "| 1925.0|     274|\n",
      "| 1926.0|     414|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT biryear as birth_year, COUNT(*) as count_by_birth_year\n",
    "    FROM i94immi_table \n",
    "    WHERE biryear IS NOT NULL\n",
    "    AND biryear <= 1926\n",
    "    GROUP BY biryear\n",
    "    ORDER BY biryear ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Total of travel trips for 90 year old and older not so much. Don't worry of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We just user records of male = 'M' and female = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM i94immi_table \n",
    "    WHERE gender IN ('F', 'M')\n",
    "\"\"\").createOrReplaceTempView(\"i94immi_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|gender_count|\n",
      "+------------+\n",
      "|     2544951|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(gender) as gender_count\n",
    "    FROM i94immi_table \n",
    "    WHERE gender IN ('F', 'M')\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|gender|count_gender|\n",
      "+------+------------+\n",
      "|     F|     1228646|\n",
      "|     M|     1316305|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT gender as gender, COUNT(*) as count_gender\n",
    "    FROM i94immi_table \n",
    "    WHERE gender IN ('F') OR gender IN ('M')\n",
    "    GROUP BY gender\n",
    "    ORDER BY gender ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cleaning i94cit (citizenship), i94res(residence) and i94addr (state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Columns **'i94cit'**, **'i94res'** and **'i94addr'** are in float datatype with meaning:\n",
    "- i94cit: Country of citizenship\n",
    "- i94res: Country of residence\n",
    "- i94addr: State code validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Just check and drop NULL values if need for these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count_null_i94cit|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_null_i94cit\n",
    "    FROM i94immi_table\n",
    "    WHERE i94cit IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|count_null_i94res|\n",
      "+-----------------+\n",
      "|                0|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_null_i94res\n",
    "    FROM i94immi_table\n",
    "    WHERE i94res IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|count_null_i94addr|\n",
      "+------------------+\n",
      "|            114019|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) as count_null_i94addr\n",
    "    FROM i94immi_table\n",
    "    WHERE i94addr IS NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Do not use i94addr cause of a lot NULL values in this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Baseline i94immi_table of data i94 immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94immi_df = spark.sql(\"\"\"\n",
    "                        SELECT *\n",
    "                        FROM i94immi_table\n",
    "                    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(cicid=15.0, i94yr=2016.0, i94mon=4.0, i94cit=101.0, i94res=101.0, i94port='WAS', arrdate=20545.0, i94mode=1.0, i94addr='MI', depdate=20691.0, i94bir=55.0, i94visa=2.0, count=1.0, dtadfile='20160401', visapost=None, occup=None, entdepa='T', entdepd='O', entdepu=None, matflag='M', biryear=1961.0, dtaddto='09302016', gender='M', insnum=None, airline='OS', admnum=666643185.0, fltno='93', visatype='B2', arrival_date=datetime.date(2016, 4, 1), departure_date='2016-08-25')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94immi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#i94immi_df.write.csv(\"i94immi_df_clean.csv\")\n",
    "i94immi_df.write.options(header='True', delimiter=',').csv(\"i94immi_df_clean\")\n",
    "#i94immi_df.write.mode('overwrite').csv(\"i94immi_df_clean\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "================================================================================================\n",
    "\n",
    "================================================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f19dfd6b1cd7fd360d4f2c4802461aa893d068ea99183b3eab6718091575a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
